{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering of Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in data\n",
    "path = '/Users/reneehall/Documents/Learning/lighthouse_labs/coursework-lighthouse-labs/Mid-term project/colab_data/'\n",
    "# test data with weather data included from Ryan\n",
    "fl_df = pd.read_csv(path+'flights_test_with_weather_data_Jan1_to_7_2020_v2.csv')\n",
    "# flights data tabel to refernce means when needed\n",
    "fl_df2 = pd.read_csv(path+'cleaned_balanced_sample.csv')\n",
    "# passengers table to reference when needed for feature creation\n",
    "pass_df = pd.read_csv(path+'cleaned_passengers.csv')\n",
    "\n",
    "# using the same feature engineering process on our test data that we used for feature creation in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target index needed for model\n",
    "\"\"\"\n",
    "Index(['index', 'mkt_carrier', 'origin', 'dest', 'origin_fl_density',\n",
    "       'dest_fl_density', 'day', 'month', 'year', 'weekday', 'crs_arr_hour',\n",
    "       'crs_dep_hour', 'predicted_speed', 'origin_num_passengers',\n",
    "       'dest_num_passengers', 'origin_num_freight', 'dest_num_freight',\n",
    "       'dist_group', 'season', 'origin_airport_size', 'dest_airport_size',\n",
    "       'mean_op_carrier_delay', 'mean_delay_origin_airport',\n",
    "       'mean_delay_dest_airport', 'sunHour', 'cloudcover', 'precipMM',\n",
    "       'hrly_bin', 'avg_hr_fl', 'avg_day_fl', 'dep_delay_lag',\n",
    "       'ddl_rolling_mean', 'mean_carrier_arr_delay', 'tail_num_arr_delay',\n",
    "       'totalSnow_mm', 'weather_type_Rainy', 'weather_type_Snowy',\n",
    "       'weather_type_Sunny'],\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'origin_fl_density'\n",
    "\n",
    "origin_daily_flights = fl_df.groupby(by=['fl_date', 'origin_airport_id']).flights.count().sort_values(ascending=False)\n",
    "# join on date and origin_airport_id\n",
    "fl_df = pd.merge(fl_df, origin_daily_flights, left_on=['fl_date','origin_airport_id'], right_on = ['fl_date','origin_airport_id'])\n",
    "fl_df.rename(columns={'flights_y': 'origin_fl_density'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dest_fl_density'\n",
    "\n",
    "dest_daily_flights = fl_df.groupby(by=['fl_date', 'dest_airport_id']).flights_x.count().sort_values(ascending=False)\n",
    "\n",
    "# join on date and origin_airport_id\n",
    "fl_df = pd.merge(fl_df, dest_daily_flights, left_on=['fl_date','dest_airport_id'], right_on = ['fl_date','dest_airport_id'])\n",
    "fl_df.rename(columns={'flights_x_x': 'flights', 'flights_x_y': 'dest_fl_density'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time features\n",
    "\n",
    "#'day', 'month', 'year', 'weekday'\n",
    "fl_df['day'] = pd.to_datetime(fl_df['fl_date']).dt.day\n",
    "fl_df['month'] = pd.to_datetime(fl_df['fl_date']).dt.month\n",
    "fl_df['year'] = pd.to_datetime(fl_df['fl_date']).dt.year\n",
    "fl_df['weekday'] = pd.to_datetime(fl_df['fl_date']).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'crs_arr_hour', 'crs_dep_hour',\n",
    "fl_df['crs_arr_hour'] = fl_df['crs_arr_time'].astype('str').str[:-2]\n",
    "fl_df['crs_arr_hour'] = fl_df.crs_arr_hour.replace('', 0)\n",
    "fl_df['crs_arr_hour'] = fl_df.crs_arr_hour.astype('int')\n",
    "\n",
    "fl_df['crs_dep_hour'] = fl_df['crs_dep_time'].astype('str').str[:-2]\n",
    "fl_df['crs_dep_hour'] = fl_df.crs_dep_hour.replace('', 0)\n",
    "fl_df['crs_dep_hour'] = fl_df.crs_dep_hour.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'predicted_speed'\n",
    "fl_df['predicted_speed'] = fl_df['distance']/fl_df['crs_elapsed_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport size\n",
    "airport_size = pass_df.groupby(by=['origin_airport_id']).sum().sort_values(by='passengers', ascending=False)\n",
    "\n",
    "# 1:small, 2:med, 3:lrg, 4, xl\n",
    "bins = [0, 100000, 1000000, 10000000, 300000000]\n",
    "labels = [1,2,3,4]\n",
    "airport_size['size'] = pd.cut(airport_size['passengers'], bins=bins, labels=labels)\n",
    "\n",
    "airport_size = airport_size[['passengers','size']]\n",
    "\n",
    "# 'origin_airport_size'\n",
    "fl_df = pd.merge(fl_df, airport_size, left_on=['origin_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.drop(labels='passengers', axis=1, inplace=True)\n",
    "fl_df.rename(columns={'size': 'origin_airport_size'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dest_airport_size'\n",
    "fl_df = pd.merge(fl_df, airport_size, left_on=['dest_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.drop(labels='passengers', axis=1, inplace=True)\n",
    "fl_df.rename(columns={'size': 'dest_airport_size'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'season'\n",
    "# winter dec-feb, spring march-may, summer june-aug, fall sep-nov\n",
    "bins = [0, 2, 5, 8, 11]\n",
    "labels = [1,2,3,4]\n",
    "fl_df['season'] = pd.cut(fl_df['month'], bins=bins, labels=labels)\n",
    "\n",
    "# binning didn't allow for dec-feb (12,1,2) so december/season was filled with np.nan\n",
    "# fill december/season with 1\n",
    "fl_df['season'] = fl_df['season'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dist_group'\n",
    "# NOTE intervals of 500, label=1 is shortest\n",
    "bins = [0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500]\n",
    "labels = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "fl_df['dist_group'] = pd.cut(fl_df['distance'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mean_op_carrier_delay'\n",
    "# take mean from sample dataset and apply to test set\n",
    "op_carrier_mean_delay = fl_df2.groupby(by=['op_unique_carrier']).arr_delay.mean().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, op_carrier_mean_delay, left_on=['op_unique_carrier'], right_on = ['op_unique_carrier'])\n",
    "fl_df.rename(columns={'arr_delay': 'mean_op_carrier_delay'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'mean_delay_origin_airport'\n",
    "# take mean from sample dataset and apply to test set\n",
    "origin_airport_mean_delay = fl_df2.groupby(by=['origin_airport_id']).arr_delay.mean()\n",
    "fl_df = pd.merge(fl_df, origin_airport_mean_delay, left_on=['origin_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.rename(columns={'arr_delay': 'mean_delay_origin_airport'}, inplace=True)\n",
    "\n",
    "fl_df = pd.merge(fl_df, origin_airport_mean_delay, left_on=['dest_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.rename(columns={'arr_delay': 'mean_delay_dest_airport'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'origin_num_passengers'\n",
    "# passengers/mo total\n",
    "pass_per_mo_origin_airport = pass_df.groupby(by=['origin_airport_id','month']).passengers.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, pass_per_mo_origin_airport, how='left', left_on=['origin_airport_id','month'], right_on = ['origin_airport_id','month'])\n",
    "fl_df.rename(columns={'passengers': 'origin_num_passengers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096.382113821138"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some missing passendger values for a size 1 origin airport; replace with mean\n",
    "size_1_mean = fl_df.loc[fl_df['origin_airport_size'] == 1].origin_num_passengers.mean()\n",
    "fl_df['origin_num_passengers'] = fl_df['origin_num_passengers'].fillna(value=size_1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dest_num_passengers'\n",
    "# passengers/mo total\n",
    "pass_per_mo_dest_airport = pass_df.groupby(by=['dest_airport_id','month']).passengers.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, pass_per_mo_dest_airport, how='left', left_on=['dest_airport_id','month'], right_on = ['dest_airport_id','month'])\n",
    "fl_df.rename(columns={'passengers': 'dest_num_passengers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some missing passendger values for a size 1 dest airport; replace with mean\n",
    "fl_df['dest_num_passengers'] = fl_df['dest_num_passengers'].fillna(value=size_1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'origin_num_freight'\n",
    "# freight/mo total\n",
    "origin_mo_freight = pass_df.groupby(by=['origin_airport_id','month']).freight.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, origin_mo_freight, how='left', left_on=['origin_airport_id','month'], right_on = ['origin_airport_id','month'])\n",
    "fl_df.rename(columns={'freight': 'origin_num_freight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60044.55894308943"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some missing freight values for a size 1 origin airport; replace with mean\n",
    "size_1_fmean = fl_df.loc[fl_df['origin_airport_size'] == 1].origin_num_freight.mean()\n",
    "fl_df['origin_num_freight'] = fl_df['origin_num_freight'].fillna(value=size_1_fmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dest_num_freight'\n",
    "dest_mo_freight = pass_df.groupby(by=['dest_airport_id','month']).freight.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, dest_mo_freight, how='left', left_on=['dest_airport_id','month'], right_on = ['dest_airport_id','month'])\n",
    "fl_df.rename(columns={'freight': 'dest_num_freight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some missing freight values for a size 1 dest airport; replace with mean\n",
    "fl_df['dest_num_freight'] = fl_df['dest_num_freight'].fillna(value=size_1_fmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the remaining features are from Tim, and this file will be passed on to him so he can incorperate them into the final test file\n",
    "    \"\"\"'hrly_bin', 'avg_hr_fl', 'avg_day_fl', 'dep_delay_lag',\n",
    "       'ddl_rolling_mean', 'mean_carrier_arr_delay', 'tail_num_arr_delay',\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "fl_df.to_csv(path+'final_test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouse",
   "language": "python",
   "name": "lighthouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
