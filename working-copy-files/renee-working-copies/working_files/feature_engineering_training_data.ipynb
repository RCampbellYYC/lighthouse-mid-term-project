{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering of Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in cleaned and balanced flights data, and passengers data\n",
    "path = '/Users/reneehall/Documents/Learning/lighthouse_labs/coursework-lighthouse-labs/Mid-term project/colab_data/'\n",
    "\n",
    "fl_df = pd.read_csv(path+'cleaned_balanced_sample.csv')\n",
    "pass_df = pd.read_csv(path+'cleaned_passengers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600000, 31)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
       "       'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name',\n",
       "       'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time', 'dep_time',\n",
       "       'dep_delay', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in',\n",
       "       'crs_arr_time', 'arr_time', 'arr_delay', 'cancelled', 'diverted',\n",
       "       'crs_elapsed_time', 'actual_elapsed_time', 'air_time', 'flights',\n",
       "       'distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm original shape and columns of flights data\n",
    "print(fl_df.shape)\n",
    "fl_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Time Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time features\n",
    "fl_df['day'] = pd.to_datetime(fl_df['fl_date']).dt.day\n",
    "fl_df['month'] = pd.to_datetime(fl_df['fl_date']).dt.month\n",
    "fl_df['year'] = pd.to_datetime(fl_df['fl_date']).dt.year\n",
    "fl_df['weekday'] = pd.to_datetime(fl_df['fl_date']).dt.weekday\n",
    "fl_df['day_of_year'] = pd.to_datetime(fl_df['fl_date']).dt.strftime('%j')\n",
    "fl_df['timestamp'] = pd.to_datetime(fl_df['fl_date']).map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arr_hour and dep_hour columns and clean\n",
    "fl_df['crs_arr_hour'] = fl_df['crs_arr_time'].astype('str').str[:-2]\n",
    "fl_df['crs_arr_hour'] = fl_df.crs_arr_hour.replace('', 0)\n",
    "fl_df['crs_arr_hour'] = fl_df.crs_arr_hour.astype('int')\n",
    "\n",
    "fl_df['crs_dep_hour'] = fl_df['crs_dep_time'].astype('str').str[:-2]\n",
    "fl_df['crs_dep_hour'] = fl_df.crs_dep_hour.replace('', 0)\n",
    "fl_df['crs_dep_hour'] = fl_df.crs_dep_hour.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival and departure during daytime\n",
    "fl_df['crs_arr_daytime'] = (fl_df['crs_arr_hour'] > 6) & (fl_df['crs_arr_hour'] < 18)\n",
    "\n",
    "fl_df['crs_dep_daytime'] = (fl_df['crs_dep_hour'] > 6) & (fl_df['crs_dep_hour'] < 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create season category\n",
    "# winter: dec-feb, spring: march-may, summer: june-aug, fall: sep-nov\n",
    "bins = [0, 2, 5, 8, 11]\n",
    "labels = [1,2,3,4]\n",
    "fl_df['season'] = pd.cut(fl_df['month'], bins=bins, labels=labels)\n",
    "\n",
    "# binning didn't allow for dec-feb (12,1,2) so december/season was filled with np.nan\n",
    "# fill december/season with 1\n",
    "fl_df['season'] = fl_df['season'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morning vs not morning flights\n",
    "# NOTE early morning (before 10am) = 1\n",
    "bins = [-1, 10, 23]\n",
    "labels = [1,0]\n",
    "fl_df['dep_early_morning'] = pd.cut(fl_df['crs_dep_hour'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight Volume Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create origin airport daily scheduled flights\n",
    "origin_daily_flights = fl_df.groupby(by=['fl_date', 'origin_airport_id']).flights.count().sort_values(ascending=False)\n",
    "\n",
    "# join on date and origin_airport_id\n",
    "fl_df = pd.merge(fl_df, origin_daily_flights, left_on=['fl_date','origin_airport_id'], right_on = ['fl_date','origin_airport_id'])\n",
    "fl_df.rename(columns={'flights_y': 'origin_fl_density'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create desination airport daily scheduled flights\n",
    "dest_daily_flights = fl_df.groupby(by=['fl_date', 'dest_airport_id']).flights_x.count().sort_values(ascending=False)\n",
    "\n",
    "# join on date and origin_airport_id\n",
    "fl_df = pd.merge(fl_df, dest_daily_flights, left_on=['fl_date','dest_airport_id'], right_on = ['fl_date','dest_airport_id'])\n",
    "fl_df.rename(columns={'flights_x_x': 'flights', 'flights_x_y': 'dest_fl_density'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed and Distance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted speed\n",
    "fl_df['predicted_speed'] = fl_df['distance']/fl_df['crs_elapsed_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create flight distance categories\n",
    "# NOTE intervals of 500, label=1 is shortest\n",
    "bins = [0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500]\n",
    "labels = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "fl_df['dist_group'] = pd.cut(fl_df['distance'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport and Size Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create category for different airport sizes by passenger volume\n",
    "airport_size = pass_df.groupby(by=['origin_airport_id']).sum().sort_values(by='passengers', ascending=False)\n",
    "\n",
    "# 1: small, 2: med, 3: lrg, 4, xl\n",
    "bins = [0, 100000, 1000000, 10000000, 300000000]\n",
    "labels = [1,2,3,4]\n",
    "airport_size['size'] = pd.cut(airport_size['passengers'], bins=bins, labels=labels)\n",
    "\n",
    "airport_size = airport_size[['passengers','size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge sizes into airport table\n",
    "# by origin airport\n",
    "fl_df = pd.merge(fl_df, airport_size, left_on=['origin_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.drop(labels='passengers', axis=1, inplace=True)\n",
    "fl_df.rename(columns={'size': 'origin_airport_size'}, inplace=True)\n",
    "\n",
    "# by destination airport\n",
    "fl_df = pd.merge(fl_df, airport_size, left_on=['dest_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.drop(labels='passengers', axis=1, inplace=True)\n",
    "fl_df.rename(columns={'size': 'dest_airport_size'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total passengers passing through origin airport per month\n",
    "pass_per_mo_origin_airport = pass_df.groupby(by=['origin_airport_id','month']).passengers.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, pass_per_mo_origin_airport, how='left', left_on=['origin_airport_id','month'], right_on = ['origin_airport_id','month'])\n",
    "fl_df.rename(columns={'passengers': 'origin_num_passengers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin_airport_size</th>\n",
       "      <th>origin_num_passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25189</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75307</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108968</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108969</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130640</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152339</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154388</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186029</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220640</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220664</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220665</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250957</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268436</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342478</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342489</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370215</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394167</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420523</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432278</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437248</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442215</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442216</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454748</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460103</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498598</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500967</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517995</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551503</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568824</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571603</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        origin_airport_id origin_airport_size  origin_num_passengers\n",
       "25189               16869                   1                    NaN\n",
       "38015               15897                   1                    NaN\n",
       "75307               15897                   1                    NaN\n",
       "108968              15897                   1                    NaN\n",
       "108969              15897                   1                    NaN\n",
       "130640              16869                   1                    NaN\n",
       "152339              16869                   1                    NaN\n",
       "154388              16869                   1                    NaN\n",
       "186029              10643                   1                    NaN\n",
       "220640              10643                   1                    NaN\n",
       "220664              15897                   1                    NaN\n",
       "220665              15897                   1                    NaN\n",
       "250957              10643                   1                    NaN\n",
       "268436              15897                   1                    NaN\n",
       "342478              10643                   1                    NaN\n",
       "342489              15897                   1                    NaN\n",
       "370215              10643                   1                    NaN\n",
       "394167              16869                   1                    NaN\n",
       "420523              15897                   1                    NaN\n",
       "432278              15897                   1                    NaN\n",
       "437248              15897                   1                    NaN\n",
       "442215              15897                   1                    NaN\n",
       "442216              15897                   1                    NaN\n",
       "454748              15897                   1                    NaN\n",
       "460103              16869                   1                    NaN\n",
       "498598              15897                   1                    NaN\n",
       "500967              16869                   1                    NaN\n",
       "517995              15897                   1                    NaN\n",
       "551503              16869                   1                    NaN\n",
       "568824              15897                   1                    NaN\n",
       "571603              15897                   1                    NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are a few airports not in passenger table will fill with means\n",
    "fl_df[['origin_airport_id','origin_airport_size','origin_num_passengers']][fl_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all missing values are from airport size one\n",
    "# calculate size 1 mean and fill nan values\n",
    "size_1_mean = fl_df.loc[fl_df['origin_airport_size'] == 1].origin_num_passengers.mean()\n",
    "fl_df['origin_num_passengers'] = fl_df['origin_num_passengers'].fillna(value=size_1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total passengers passing through destination airport per month\n",
    "pass_per_mo_dest_airport = pass_df.groupby(by=['dest_airport_id','month']).passengers.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, pass_per_mo_dest_airport, how='left', left_on=['dest_airport_id','month'], right_on = ['dest_airport_id','month'])\n",
    "fl_df.rename(columns={'passengers': 'dest_num_passengers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest_airport_size</th>\n",
       "      <th>dest_num_passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596542</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596543</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596545</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596546</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596547</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596548</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596549</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596550</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596551</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596553</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596554</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596556</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596557</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596560</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596561</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596562</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596563</th>\n",
       "      <td>15897</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599531</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599533</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599535</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599536</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599538</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599540</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599541</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599542</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599543</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599545</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599546</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599548</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599549</th>\n",
       "      <td>16869</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599975</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599976</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599982</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599985</th>\n",
       "      <td>10643</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dest_airport_id dest_airport_size  dest_num_passengers\n",
       "596542            15897                 1                  NaN\n",
       "596543            15897                 1                  NaN\n",
       "596545            15897                 1                  NaN\n",
       "596546            15897                 1                  NaN\n",
       "596547            15897                 1                  NaN\n",
       "596548            15897                 1                  NaN\n",
       "596549            15897                 1                  NaN\n",
       "596550            15897                 1                  NaN\n",
       "596551            15897                 1                  NaN\n",
       "596553            15897                 1                  NaN\n",
       "596554            15897                 1                  NaN\n",
       "596556            15897                 1                  NaN\n",
       "596557            15897                 1                  NaN\n",
       "596560            15897                 1                  NaN\n",
       "596561            15897                 1                  NaN\n",
       "596562            15897                 1                  NaN\n",
       "596563            15897                 1                  NaN\n",
       "599531            16869                 1                  NaN\n",
       "599533            16869                 1                  NaN\n",
       "599535            16869                 1                  NaN\n",
       "599536            16869                 1                  NaN\n",
       "599538            16869                 1                  NaN\n",
       "599540            16869                 1                  NaN\n",
       "599541            16869                 1                  NaN\n",
       "599542            16869                 1                  NaN\n",
       "599543            16869                 1                  NaN\n",
       "599545            16869                 1                  NaN\n",
       "599546            16869                 1                  NaN\n",
       "599548            16869                 1                  NaN\n",
       "599549            16869                 1                  NaN\n",
       "599975            10643                 1                  NaN\n",
       "599976            10643                 1                  NaN\n",
       "599982            10643                 1                  NaN\n",
       "599985            10643                 1                  NaN"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are a few airports not in passenger table will fill with means\n",
    "fl_df[['dest_airport_id','dest_airport_size','dest_num_passengers']][fl_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, all missing values are from airport size one, fill with sz.1 mean\n",
    "size_1_mean = fl_df.loc[fl_df['dest_airport_size'] == 1].dest_num_passengers.mean()\n",
    "fl_df['dest_num_passengers'] = fl_df['dest_num_passengers'].fillna(value=size_1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total freight handled per month by origin airport\n",
    "origin_mo_freight = pass_df.groupby(by=['origin_airport_id','month']).freight.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, origin_mo_freight, how='left', left_on=['origin_airport_id','month'], right_on = ['origin_airport_id','month'])\n",
    "fl_df.rename(columns={'freight': 'origin_num_freight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest_airport_size</th>\n",
       "      <th>dest_num_passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25189</th>\n",
       "      <td>11292</td>\n",
       "      <td>4</td>\n",
       "      <td>13862688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38015</th>\n",
       "      <td>12953</td>\n",
       "      <td>4</td>\n",
       "      <td>6305561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75307</th>\n",
       "      <td>13930</td>\n",
       "      <td>4</td>\n",
       "      <td>15773756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108968</th>\n",
       "      <td>10397</td>\n",
       "      <td>4</td>\n",
       "      <td>21126951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108969</th>\n",
       "      <td>10397</td>\n",
       "      <td>4</td>\n",
       "      <td>22197627.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130640</th>\n",
       "      <td>14747</td>\n",
       "      <td>4</td>\n",
       "      <td>10866897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152339</th>\n",
       "      <td>13198</td>\n",
       "      <td>4</td>\n",
       "      <td>2542075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154388</th>\n",
       "      <td>10140</td>\n",
       "      <td>4</td>\n",
       "      <td>1167028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186029</th>\n",
       "      <td>11057</td>\n",
       "      <td>4</td>\n",
       "      <td>9822201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220640</th>\n",
       "      <td>11298</td>\n",
       "      <td>4</td>\n",
       "      <td>13757687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220664</th>\n",
       "      <td>11298</td>\n",
       "      <td>4</td>\n",
       "      <td>13436387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220665</th>\n",
       "      <td>11298</td>\n",
       "      <td>4</td>\n",
       "      <td>13127044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250957</th>\n",
       "      <td>11278</td>\n",
       "      <td>4</td>\n",
       "      <td>4993868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268436</th>\n",
       "      <td>11003</td>\n",
       "      <td>3</td>\n",
       "      <td>209378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342478</th>\n",
       "      <td>12266</td>\n",
       "      <td>4</td>\n",
       "      <td>8924625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342489</th>\n",
       "      <td>12266</td>\n",
       "      <td>4</td>\n",
       "      <td>8246291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370215</th>\n",
       "      <td>13232</td>\n",
       "      <td>4</td>\n",
       "      <td>3282786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394167</th>\n",
       "      <td>14100</td>\n",
       "      <td>4</td>\n",
       "      <td>7278547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420523</th>\n",
       "      <td>12478</td>\n",
       "      <td>4</td>\n",
       "      <td>9598210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432278</th>\n",
       "      <td>14761</td>\n",
       "      <td>3</td>\n",
       "      <td>546327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437248</th>\n",
       "      <td>10423</td>\n",
       "      <td>4</td>\n",
       "      <td>3021591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442215</th>\n",
       "      <td>14831</td>\n",
       "      <td>4</td>\n",
       "      <td>2667147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442216</th>\n",
       "      <td>14831</td>\n",
       "      <td>4</td>\n",
       "      <td>2090546.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454748</th>\n",
       "      <td>14057</td>\n",
       "      <td>4</td>\n",
       "      <td>2988924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460103</th>\n",
       "      <td>14307</td>\n",
       "      <td>3</td>\n",
       "      <td>840880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498598</th>\n",
       "      <td>11042</td>\n",
       "      <td>4</td>\n",
       "      <td>1792675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500967</th>\n",
       "      <td>11540</td>\n",
       "      <td>3</td>\n",
       "      <td>694314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517995</th>\n",
       "      <td>10792</td>\n",
       "      <td>4</td>\n",
       "      <td>1044855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551503</th>\n",
       "      <td>10257</td>\n",
       "      <td>3</td>\n",
       "      <td>618392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568824</th>\n",
       "      <td>15323</td>\n",
       "      <td>3</td>\n",
       "      <td>82498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571603</th>\n",
       "      <td>13277</td>\n",
       "      <td>2</td>\n",
       "      <td>59845.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dest_airport_id dest_airport_size  dest_num_passengers\n",
       "25189             11292                 4           13862688.0\n",
       "38015             12953                 4            6305561.0\n",
       "75307             13930                 4           15773756.0\n",
       "108968            10397                 4           21126951.0\n",
       "108969            10397                 4           22197627.0\n",
       "130640            14747                 4           10866897.0\n",
       "152339            13198                 4            2542075.0\n",
       "154388            10140                 4            1167028.0\n",
       "186029            11057                 4            9822201.0\n",
       "220640            11298                 4           13757687.0\n",
       "220664            11298                 4           13436387.0\n",
       "220665            11298                 4           13127044.0\n",
       "250957            11278                 4            4993868.0\n",
       "268436            11003                 3             209378.0\n",
       "342478            12266                 4            8924625.0\n",
       "342489            12266                 4            8246291.0\n",
       "370215            13232                 4            3282786.0\n",
       "394167            14100                 4            7278547.0\n",
       "420523            12478                 4            9598210.0\n",
       "432278            14761                 3             546327.0\n",
       "437248            10423                 4            3021591.0\n",
       "442215            14831                 4            2667147.0\n",
       "442216            14831                 4            2090546.0\n",
       "454748            14057                 4            2988924.0\n",
       "460103            14307                 3             840880.0\n",
       "498598            11042                 4            1792675.0\n",
       "500967            11540                 3             694314.0\n",
       "517995            10792                 4            1044855.0\n",
       "551503            10257                 3             618392.0\n",
       "568824            15323                 3              82498.0\n",
       "571603            13277                 2              59845.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are a few airports not in passenger table will fill with freight means\n",
    "fl_df[['dest_airport_id','dest_airport_size','dest_num_passengers']][fl_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need freight means for sizes 4\n",
    "size_4_fmean = fl_df.loc[fl_df['origin_airport_size'] == 4].origin_num_freight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan's with mean\n",
    "fl_df['origin_num_freight'] = fl_df['origin_num_freight'].fillna(value=size_4_fmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total freight handled per month by destination airport\n",
    "dest_mo_freight = pass_df.groupby(by=['dest_airport_id','month']).freight.sum().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, dest_mo_freight, how='left', left_on=['dest_airport_id','month'], right_on = ['dest_airport_id','month'])\n",
    "fl_df.rename(columns={'freight': 'dest_num_freight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, replacing freight nans\n",
    "fl_df['dest_num_freight'] = fl_df['dest_num_freight'].fillna(value=size_4_fmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport and Carrier Aggregation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean arrival delay by carrier\n",
    "op_carrier_mean_delay = fl_df.groupby(by=['op_unique_carrier']).arr_delay.mean().sort_values(ascending=False)\n",
    "fl_df = pd.merge(fl_df, op_carrier_mean_delay, left_on=['op_unique_carrier'], right_on = ['op_unique_carrier'])\n",
    "\n",
    "fl_df.rename(columns={'arr_delay_y': 'mean_op_carrier_delay'}, inplace=True)\n",
    "fl_df.rename(columns={'arr_delay_x': 'arr_delay'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean arrival delay by airport\n",
    "# calculate mean delays\n",
    "origin_airport_mean_delay = fl_df.groupby(by=['origin_airport_id']).arr_delay.mean()\n",
    "\n",
    "# match origin airport mean delay\n",
    "fl_df = pd.merge(fl_df, origin_airport_mean_delay, left_on=['origin_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.rename(columns={'arr_delay_x': 'arr_delay'}, inplace=True)\n",
    "fl_df.rename(columns={'arr_delay_y': 'mean_delay_origin_airport'}, inplace=True)\n",
    "\n",
    "# match delays of destination airports\n",
    "fl_df = pd.merge(fl_df, origin_airport_mean_delay, left_on=['dest_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.rename(columns={'arr_delay_x': 'arr_delay'}, inplace=True)\n",
    "fl_df.rename(columns={'arr_delay_y': 'mean_delay_dest_airport'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean monthly arrival delay by airport\n",
    "# calculate mean\n",
    "origin_airport_mo_mean_delay = fl_df.groupby(by=['origin_airport_id', 'month']).arr_delay.mean()\n",
    "\n",
    "# match mean to origin airports\n",
    "fl_df = pd.merge(fl_df, origin_airport_mo_mean_delay, how='left', left_on=['origin_airport_id','month'], right_on = ['origin_airport_id', 'month'])\n",
    "fl_df.rename(columns={'arr_delay_x': 'arr_delay'}, inplace=True)\n",
    "fl_df.rename(columns={'arr_delay_y': 'mean_mo_delay_origin_airport'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean departure delay by airport\n",
    "origin_mean_dep_delay = fl_df.groupby(by=['origin_airport_id']).dep_delay.mean()\n",
    "\n",
    "# match dep delay for origins\n",
    "fl_df = pd.merge(fl_df, origin_mean_dep_delay, left_on=['origin_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.rename(columns={'dep_delay_x': 'dep_delay'}, inplace=True)\n",
    "fl_df.rename(columns={'dep_delay_y': 'mean_dep_delay_origin'}, inplace=True)\n",
    "\n",
    "# match dep delay for destinations\n",
    "fl_df = pd.merge(fl_df, origin_mean_dep_delay, left_on=['dest_airport_id'], right_on = ['origin_airport_id'])\n",
    "fl_df.rename(columns={'dep_delay_x': 'dep_delay'}, inplace=True)\n",
    "fl_df.rename(columns={'dep_delay_y': 'mean_dep_delay_dest'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ratio of the arrival delay that can be accounted for by the departure delay\n",
    "\n",
    "# create a few columns to be used in aggregations\n",
    "# percent of arrival accounted for by departure delay for each flight\n",
    "fl_df['percent_delay_dep'] = (fl_df['dep_delay']/(fl_df['dep_delay'] + fl_df['arr_delay']))\n",
    "# fix some value errors caused by zero division\n",
    "fl_df['percent_delay_dep'] = fl_df['percent_delay_dep'].fillna(0.0)\n",
    "fl_df['percent_delay_dep'] = fl_df['percent_delay_dep'].replace([np.inf, -np.inf], 0.0)\n",
    "# ratio of arrival delay to predictedflight time\n",
    "fl_df['delay_time_ratio'] = fl_df['arr_delay']/fl_df['crs_elapsed_time']\n",
    "\n",
    "# delay:flight time ratio averaged by distance group\n",
    "delay_types = fl_df.groupby(by=['dist_group']).delay_time_ratio.mean()\n",
    "fl_df = pd.merge(fl_df, delay_types, left_on=['dist_group'], right_on = ['dist_group'])\n",
    "fl_df.rename(columns={'delay_time_ratio_y': 'dist_group_delay_ratio'}, inplace=True)\n",
    "fl_df.drop(labels=['delay_time_ratio_x'],axis=1, inplace=True)\n",
    "\n",
    "# percent_dep_delay grouped by carrier & airport\n",
    "per_dep_delay = fl_df.groupby(by=['op_unique_carrier', 'origin_airport_id']).percent_delay_dep.mean().sort_values()\n",
    "fl_df = pd.merge(fl_df, per_dep_delay, how='left',left_on=['origin_airport_id','op_unique_carrier'], right_on = ['origin_airport_id','op_unique_carrier'])\n",
    "fl_df.rename(columns={'percent_delay_dep_x_y': 'ap_carr_percent_dep_delay'}, inplace=True)\n",
    "fl_df.rename(columns={'percent_delay_dep_x_x': 'percent_dep_delay'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent of flights delayed by distance group\n",
    "dist_group_df = fl_df[['dist_group', 'flights']].groupby(by=['dist_group']).count()\n",
    "dist_group_df['delayed'] = fl_df.loc[fl_df['arr_delay'] > 0.0].groupby(by=['dist_group']).flights.count()\n",
    "dist_group_df['percent_delayed'] = dist_group_df.delayed/dist_group_df.flights * 100\n",
    "fl_df = pd.merge(fl_df, dist_group_df['percent_delayed'], left_on=['dist_group'], right_on = ['dist_group'])\n",
    "fl_df.rename(columns={'percent_delayed': 'dist_group_percent_delayed'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Shape and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 63)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm same number of rows\n",
    "fl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crs_elapsed_time              0\n",
       "actual_elapsed_time           0\n",
       "air_time                      0\n",
       "dep_time                      0\n",
       "dist_group_percent_delayed    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "fl_df.isnull().sum().sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv \n",
    "fl_df.to_csv(path+'balanced_more_flight_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create smaller 50,000 row set for ease of modeling\n",
    "sm_df = fl_df.sample(50000, random_state=26)\n",
    "sm_df.to_csv(path+'mini_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lighthouse",
   "language": "python",
   "name": "lighthouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
